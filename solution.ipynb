{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence            entities  \\\n",
      "0  The most common <e1>audits</e1> were about <e2...     [audits, waste]   \n",
      "1  The school <e1>master</e1> teaches the lesson ...     [master, stick]   \n",
      "2  Avian <e1>influenza</e1> is an infectious dise...  [influenza, virus]   \n",
      "3  A child is told a <e1>lie</e1> for several yea...      [lie, parents]   \n",
      "4  The disgusting scene was retaliation against h...       [room, house]   \n",
      "\n",
      "                                            relation  \n",
      "0  8002\\t\"The <e1>company</e1> fabricates plastic...  \n",
      "1  8004\\t\"The suspect dumped the dead <e1>body</e...  \n",
      "2  8006\\t\"The <e1>ear</e1> of the African <e2>ele...  \n",
      "3  8008\\t\"Skype, a free software, allows a <e1>ho...  \n",
      "4  8010\\t\"This <e1>thesis</e1> defines the <e2>cl...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# Caricare il modello di spaCy per l'analisi sintattica e semantica\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Definire le relazioni esistenti nel dataset\n",
    "RELATIONS = [\n",
    "    \"Cause-Effect\", \"Instrument-Agency\", \"Product-Producer\", \"Content-Container\",\n",
    "    \"Entity-Origin\", \"Entity-Destination\", \"Component-Whole\", \"Member-Collection\",\n",
    "    \"Message-Topic\", \"Other\"\n",
    "]\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for i in range(0, len(lines), 2):  # Ogni esempio è su 2 righe (frase + relazione)\n",
    "        if '\"' in lines[i]:  \n",
    "            sentence = re.findall(r'\"(.*?)\"', lines[i])[0]\n",
    "            relation = lines[i + 1].strip() if i + 1 < len(lines) else \"Other\"\n",
    "            entities = re.findall(r'<e1>(.*?)</e1>', lines[i]) + re.findall(r'<e2>(.*?)</e2>', lines[i])\n",
    "            data.append({'sentence': sentence, 'entities': entities, 'relation': relation})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Caricare i dati\n",
    "train_df = load_data('data/TRAIN_FILE.TXT')\n",
    "test_df = load_data('data/TEST_FILE.txt')\n",
    "\n",
    "# Mostra le prime righe per verifica\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### l'idea che ho avuto è di prendere il verbo e di controllarne il prefisso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  \\\n",
      "0  The system as described above has its greatest...   \n",
      "1  The <e1>child</e1> was carefully wrapped and b...   \n",
      "2  The <e1>author</e1> of a keygen uses a <e2>dis...   \n",
      "3  A misty <e1>ridge</e1> uprises from the <e2>su...   \n",
      "4  The <e1>student</e1> <e2>association</e2> is t...   \n",
      "\n",
      "                    entities predicted_relation  \n",
      "0  [configuration, elements]              Other  \n",
      "1            [child, cradle]              Other  \n",
      "2     [author, disassembler]  Instrument-Agency  \n",
      "3             [ridge, surge]              Other  \n",
      "4     [student, association]              Other  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Caricare il modello di spaCy per il POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def classify_relation_using_verb(sentence, entities):\n",
    "    # Controllare se entities contiene esattamente due elementi\n",
    "    if len(entities) != 2:\n",
    "        return \"Other\"  # Se non ci sono esattamente due entità, ritorna \"Other\"\n",
    "\n",
    "    # Analizzare la frase con spaCy\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Estrarre e1 ed e2 dalle entità\n",
    "    e1, e2 = entities\n",
    "\n",
    "    # Trova il verbo tra e1 e e2\n",
    "    verb = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb = token.lemma_\n",
    "            break  # Prendiamo il primo verbo che troviamo tra e1 ed e2\n",
    "\n",
    "    # Controllare il verbo per determinare la relazione\n",
    "    if verb:\n",
    "        if verb in [\"cause\", \"lead\", \"result\"]:\n",
    "            return \"Cause-Effect\"\n",
    "        elif verb in [\"use\", \"operate\"]:\n",
    "            return \"Instrument-Agency\"\n",
    "        elif verb in [\"make\", \"produce\", \"manufacture\", \"create\"]:\n",
    "            return \"Product-Producer\"\n",
    "        elif verb in [\"contain\", \"inside\"]:\n",
    "            return \"Content-Container\"\n",
    "        elif verb in [\"originate\", \"from\"]:\n",
    "            return \"Entity-Origin\"\n",
    "        elif verb in [\"move\", \"to\"]:\n",
    "            return \"Entity-Destination\"\n",
    "        elif verb in [\"part of\", \"include\"]:\n",
    "            return \"Component-Whole\"\n",
    "        elif verb in [\"belong\", \"member of\"]:\n",
    "            return \"Member-Collection\"\n",
    "        elif verb in [\"talk\", \"topic\"]:\n",
    "            return \"Message-Topic\"\n",
    "    \n",
    "    return \"Other\"  # Se nessun verbo corrisponde\n",
    "\n",
    "# Applicare la funzione al training set\n",
    "train_df['predicted_relation'] = train_df.apply(lambda row: classify_relation_using_verb(row['sentence'], row['entities']), axis=1)\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(train_df[['sentence', 'entities', 'predicted_relation']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.15%\n",
      "                        Class  Precision    Recall  F1-Score  Support\n",
      "0      Component-Whole(e2,e1)   0.000000  0.000000  0.000000      471\n",
      "1                       Other   0.181102  0.929787  0.303156     1410\n",
      "2    Instrument-Agency(e2,e1)   0.000000  0.000000  0.000000      407\n",
      "3    Member-Collection(e1,e2)   0.000000  0.000000  0.000000       78\n",
      "4         Cause-Effect(e2,e1)   0.000000  0.000000  0.000000      659\n",
      "5   Entity-Destination(e1,e2)   0.000000  0.000000  0.000000      844\n",
      "6    Content-Container(e1,e2)   0.000000  0.000000  0.000000      374\n",
      "7        Message-Topic(e1,e2)   0.000000  0.000000  0.000000      490\n",
      "8     Product-Producer(e2,e1)   0.000000  0.000000  0.000000      394\n",
      "9    Member-Collection(e2,e1)   0.000000  0.000000  0.000000      612\n",
      "10       Entity-Origin(e1,e2)   0.000000  0.000000  0.000000      568\n",
      "11        Cause-Effect(e1,e2)   0.000000  0.000000  0.000000      344\n",
      "12                              0.000000  0.000000  0.000000      118\n",
      "13     Component-Whole(e1,e2)   0.000000  0.000000  0.000000      470\n",
      "14       Message-Topic(e2,e1)   0.000000  0.000000  0.000000      144\n",
      "15    Product-Producer(e1,e2)   0.000000  0.000000  0.000000      323\n",
      "16       Entity-Origin(e2,e1)   0.000000  0.000000  0.000000      148\n",
      "17   Content-Container(e2,e1)   0.000000  0.000000  0.000000      166\n",
      "18   Instrument-Agency(e1,e2)   0.000000  0.000000  0.000000       97\n",
      "19  Entity-Destination(e2,e1)   0.000000  0.000000  0.000000        1\n",
      "Macro F1-Score: 0.02\n",
      "Weighted F1-Score: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Calcolare l'accuratezza\n",
    "accuracy = accuracy_score(train_df['relation'], train_df['predicted_relation'])\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calcolare Precision, Recall e F1-Score per ciascuna classe\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    train_df['relation'], train_df['predicted_relation'], average=None, labels=train_df['relation'].unique()\n",
    ")\n",
    "\n",
    "# Visualizzare i risultati delle metriche per ogni classe\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': train_df['relation'].unique(),\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "# Calcolare la F1-Score macro-media\n",
    "macro_f1 = f1.mean()\n",
    "print(f\"Macro F1-Score: {macro_f1:.2f}\")\n",
    "\n",
    "# Calcolare la F1-Score pesata\n",
    "weighted_f1 = (precision * support).sum() / support.sum()\n",
    "print(f\"Weighted F1-Score: {weighted_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature vector + machine learning solution based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione del feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence_length  has_verb_prefix_cause  has_verb_prefix_use  \\\n",
      "0               16                      0                    0   \n",
      "1               15                      0                    0   \n",
      "2               15                      0                    1   \n",
      "3               12                      0                    0   \n",
      "4               35                      1                    0   \n",
      "\n",
      "   has_verb_prefix_make  has_verb_prefix_contain  has_verb_prefix_originate  \\\n",
      "0                     0                        0                          0   \n",
      "1                     0                        0                          0   \n",
      "2                     0                        0                          0   \n",
      "3                     0                        0                          0   \n",
      "4                     0                        0                          0   \n",
      "\n",
      "   has_verb_prefix_move  has_verb_prefix_part  has_verb_prefix_belong  \\\n",
      "0                     0                     0                       0   \n",
      "1                     0                     0                       0   \n",
      "2                     0                     0                       0   \n",
      "3                     0                     0                       0   \n",
      "4                     0                     0                       0   \n",
      "\n",
      "   has_verb_prefix_talk           actual_relation  \n",
      "0                     0    Component-Whole(e2,e1)  \n",
      "1                     0                     Other  \n",
      "2                     0  Instrument-Agency(e2,e1)  \n",
      "3                     0                     Other  \n",
      "4                     0       Cause-Effect(e2,e1)  \n",
      "82995\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Caricare il modello di spaCy per il POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Funzione per estrarre il verbo e creare un feature vector\n",
    "def extract_features_based_on_verb(sentence, entities):\n",
    "    # Controllare se entities contiene esattamente due entità\n",
    "    if len(entities) != 2:\n",
    "        return None  # Se non ci sono esattamente due entità, non possiamo estrarre caratteristiche\n",
    "\n",
    "    sentence = re.sub(r'<e1>|</e1>|<e2>|</e2>', '', sentence)\n",
    "    # Analizzare la frase con spaCy\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Estrarre e1 ed e2 dalle entità\n",
    "    e1, e2 = entities\n",
    "\n",
    "    # Trova il verbo tra e1 e e2\n",
    "    verb = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb = token.lemma_\n",
    "            break  # Prendiamo il primo verbo che troviamo tra e1 ed e2\n",
    "\n",
    "    # Se non è stato trovato un verbo tra le entità, ritorna None\n",
    "    if not verb:\n",
    "        return None\n",
    "\n",
    "    # Creazione di un feature vector\n",
    "    feature_vector = {\n",
    "        #\"e1\": e1,  --------> not numerical feature\n",
    "        #\"e2\": e2,\n",
    "        #\"verb\": verb,\n",
    "        #\"verb_lemma\": token.lemma_,\n",
    "        #\"verb_pos\": token.pos_,\n",
    "        \"sentence_length\": len(sentence.split()),  # Numero di parole nella frase\n",
    "        \"has_verb_prefix_cause\": 1 if verb in [\"cause\", \"lead\", \"result\"] else 0,\n",
    "        \"has_verb_prefix_use\": 1 if verb in [\"use\", \"operate\"] else 0,\n",
    "        \"has_verb_prefix_make\": 1 if verb in [\"make\", \"produce\", \"manufacture\", \"create\"] else 0,\n",
    "        \"has_verb_prefix_contain\": 1 if verb in [\"contain\", \"inside\"] else 0,\n",
    "        \"has_verb_prefix_originate\": 1 if verb in [\"originate\", \"from\"] else 0,\n",
    "        \"has_verb_prefix_move\": 1 if verb in [\"move\", \"to\"] else 0,\n",
    "        \"has_verb_prefix_part\": 1 if verb in [\"part of\", \"include\"] else 0,\n",
    "        \"has_verb_prefix_belong\": 1 if verb in [\"belong\", \"member of\"] else 0,\n",
    "        \"has_verb_prefix_talk\": 1 if verb in [\"talk\", \"topic\"] else 0\n",
    "    }\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "# Applicare la funzione al training set per creare il feature vector\n",
    "train_features = []\n",
    "for _, row in train_df.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    entities = row['entities']\n",
    "    feature_vector = extract_features_based_on_verb(sentence, entities)\n",
    "    \n",
    "    if feature_vector:  # Aggiungi solo se c'è un feature vector\n",
    "        feature_vector['actual_relation'] = row['relation']\n",
    "        train_features.append(feature_vector)\n",
    "\n",
    "# Creazione del dataframe con i feature vectors\n",
    "train_feature_df = pd.DataFrame(train_features)\n",
    "\n",
    "# Visualizza i primi 5 feature vector\n",
    "print(train_feature_df.head())\n",
    "print(train_feature_df.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2339\n",
      "Confusion Matrix:\n",
      "[[  0  38   0   0   0   2   7   0   0   0   0   0   0   0   0  29   0   0]\n",
      " [  0  32   0   1   0   0   8   0   0   0   0   0   0   0   0  74   0   0]\n",
      " [  0   0   0   0   0   1  13   0   0   0   4   0   0   0   0  66   0   0]\n",
      " [  0   0   0   5   0   6  17   0   0   0   3   0   0   0   0  61   0   0]\n",
      " [  0   0   0   1   0   8   7   0   0   0   1   0   0   0   0  38   0   0]\n",
      " [  0   0   0   2   0   3   4   0   0   0   0   0   0   0   0  18   0   0]\n",
      " [  0   0   0   0   0   0 118   0   0   0   0   0   0   0   0  40   0   0]\n",
      " [  0   0   0   0   0   0  32   2   0   0   0   0   0   0   0  69   0   0]\n",
      " [  0   0   0   1   0   0   3   0   0   0   3   0   0   0   0  14   0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0   5   0   0   0   0   9   0   0]\n",
      " [  0   0   0   0   0   0  25   0   0   0   7   0   0   0   0  50   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   1   0   0   0   0  10   0   0]\n",
      " [  0   2   0   0   0   1  10   0   0   0   3   0   0   0   0 103   0   0]\n",
      " [  0   1   0   1   0   2  34   0   0   0   2   0   0   0   0  57   0   0]\n",
      " [  0   0   0   0   0   0  11   0   0   0   0   0   0   0   0  15   0   0]\n",
      " [  0   3   0   2   0   0  88   0   0   0   3   0   0   0   0 186   0   0]\n",
      " [  0   1   0   0   0   0   7   0   0   0   2   0   0   0   0  51   0   0]\n",
      " [  0   1   0   0   0   0  10   0   0   0   1   0   0   0   0  71   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Cause-Effect(e1,e2)       0.00      0.00      0.00        76\n",
      "      Cause-Effect(e2,e1)       0.41      0.28      0.33       115\n",
      "   Component-Whole(e1,e2)       0.00      0.00      0.00        84\n",
      "   Component-Whole(e2,e1)       0.38      0.05      0.10        92\n",
      " Content-Container(e1,e2)       0.00      0.00      0.00        55\n",
      " Content-Container(e2,e1)       0.13      0.11      0.12        27\n",
      "Entity-Destination(e1,e2)       0.30      0.75      0.43       158\n",
      "     Entity-Origin(e1,e2)       1.00      0.02      0.04       103\n",
      "     Entity-Origin(e2,e1)       0.00      0.00      0.00        21\n",
      " Instrument-Agency(e1,e2)       0.00      0.00      0.00        16\n",
      " Instrument-Agency(e2,e1)       0.20      0.09      0.12        82\n",
      " Member-Collection(e1,e2)       0.00      0.00      0.00        12\n",
      " Member-Collection(e2,e1)       0.00      0.00      0.00       119\n",
      "     Message-Topic(e1,e2)       0.00      0.00      0.00        97\n",
      "     Message-Topic(e2,e1)       0.00      0.00      0.00        26\n",
      "                    Other       0.19      0.66      0.30       282\n",
      "  Product-Producer(e1,e2)       0.00      0.00      0.00        61\n",
      "  Product-Producer(e2,e1)       0.00      0.00      0.00        83\n",
      "\n",
      "                 accuracy                           0.23      1509\n",
      "                macro avg       0.15      0.11      0.08      1509\n",
      "             weighted avg       0.20      0.23      0.14      1509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mf/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assicurati che la colonna di relazione (target) sia separata\n",
    "X = train_feature_df.drop(columns=['actual_relation'])  # Le caratteristiche\n",
    "y = train_feature_df['actual_relation']  # Le etichette (relazioni effettive)\n",
    "\n",
    "# Suddividere i dati in training e validation set (80% / 20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creare il modello SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Allenare il modello\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predire le etichette sul set di validazione\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Calcolare l'accuratezza\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Matrice di confusione\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Report di classificazione\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
